{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relevant-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained models available:\n",
      "Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt\n",
      "improved_sudo_epoch_500\n",
      "GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt\n",
      "Improved_Sudormrf_U16_Bases512_WSJ02mix.pt\n",
      "Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt\n",
      "Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from asteroid.metrics import get_metrics\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get the pretrained models\n",
    "print(\"Pre-trained models available:\")\n",
    "for model_name in os.listdir('../../pretrained_models'):\n",
    "    print(model_name)\n",
    "    \n",
    "def normalize_tensor_wav(wav_tensor, eps=1e-8, std=None):\n",
    "    mean = wav_tensor.mean(-1, keepdim=True)\n",
    "    if std is None:\n",
    "        std = wav_tensor.std(-1, keepdim=True)\n",
    "    return (wav_tensor - mean) / (std + eps)\n",
    "    \n",
    "anechoic_model_p = '../../pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt'\n",
    "anechoic_model_p = '../../pretrained_models/Improved_Sudormrf_U16_Bases512_WSJ02mix.pt'\n",
    "anechoic_model_p = '../../pretrained_models/Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt'\n",
    "noisy_reverberant_model_p = '../../pretrained_models/Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt'\n",
    "noisy_reverberant_model_p = '../../pretrained_models/Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt'\n",
    "\n",
    "# Load the appropriate class modules\n",
    "sys.path.append(\"../../\")\n",
    "import sudo_rm_rf.dnn.models.improved_sudormrf as improved_sudormrf\n",
    "import sudo_rm_rf.dnn.models.groupcomm_sudormrf_v2 as sudormrf_gc_v2\n",
    "import sudo_rm_rf.dnn.models.sepformer as sepformer\n",
    "from speechbrain.pretrained import SepformerSeparation as sep_former_separator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "magnetic-chester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39001]) torch.Size([2, 39001])\n"
     ]
    }
   ],
   "source": [
    "# get all files for wham or whamr!\n",
    "whamr_test_folder_path = '/mnt/data/whamr/wav8k/min/tt'\n",
    "wsj02mix_test_file_names = os.listdir(os.path.join(whamr_test_folder_path, 'mix_clean_anechoic')) \n",
    "whamrexcl_test_file_names = os.listdir(os.path.join(whamr_test_folder_path, 'mix_both_reverb')) \n",
    "wsj02mix_test_file_names = [os.path.join(whamr_test_folder_path, 'mix_clean_anechoic',name)\n",
    "                            for name in wsj02mix_test_file_names]\n",
    "whamrexcl_test_file_names = [os.path.join(whamr_test_folder_path, 'mix_both_reverb',name)\n",
    "                             for name in wsj02mix_test_file_names]\n",
    "\n",
    "def get_tensors_for_chosen_file(chosen_mixture_path):\n",
    "    mixture, _ = torchaudio.load(chosen_mixture_path)\n",
    "    chosen_filename = os.path.basename(chosen_mixture_path)\n",
    "    ground_truth_sources = torch.tensor(np.array([\n",
    "        torchaudio.load(os.path.join(whamr_test_folder_path,\n",
    "                                     's1_anechoic', chosen_filename))[0].detach().numpy()[0],\n",
    "        torchaudio.load(os.path.join(whamr_test_folder_path,\n",
    "                                     's2_anechoic', chosen_filename))[0].detach().numpy()[0]\n",
    "    ]))\n",
    "    \n",
    "    return mixture[:, :56000], ground_truth_sources[:, :56000]\n",
    "    \n",
    "chosen_file = '446o030h_0.13806_444c020w_-0.13806.wav'\n",
    "chosen_mixture_path = os.path.join(whamr_test_folder_path, 'mix_clean_anechoic', chosen_file)\n",
    "print(get_tensors_for_chosen_file(chosen_mixture_path)[0].shape,\n",
    "get_tensors_for_chosen_file(chosen_mixture_path)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-nepal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Evaluating model: GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 747/3000 [11:58<38:06,  1.01s/it]"
     ]
    }
   ],
   "source": [
    "models_to_eval = [\n",
    "    {\n",
    "        'model_path': '../../pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt',\n",
    "        'is_sudo_model': True,\n",
    "        'test_dataset': \"WSJ02mix\",\n",
    "    },\n",
    "    {\n",
    "        'model_path': '../../pretrained_models/Improved_Sudormrf_U16_Bases512_WSJ02mix.pt',\n",
    "        'is_sudo_model': True,\n",
    "        'test_dataset': \"WSJ02mix\",\n",
    "    },\n",
    "    {\n",
    "        'model_path': '../../pretrained_models/Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt',\n",
    "        'is_sudo_model': True,\n",
    "        'test_dataset': \"WSJ02mix\",\n",
    "    },\n",
    "    {\n",
    "        'model_path': '../../pretrained_models/Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt',\n",
    "        'is_sudo_model': True,\n",
    "        'test_dataset': \"WHAMR!\",\n",
    "    },\n",
    "    {\n",
    "        'model_path': '../../pretrained_models/Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt',\n",
    "        'is_sudo_model': True,\n",
    "        'test_dataset': \"WHAMR!\",\n",
    "    },\n",
    "    {\n",
    "        'model_path': None,\n",
    "        'is_sudo_model': False,\n",
    "        'test_dataset': \"WSJ02mix\",\n",
    "    }\n",
    "]\n",
    "\n",
    "def normalize_tensor_wav(wav_tensor, eps=1e-8, std=None):\n",
    "    mean = wav_tensor.mean(-1, keepdim=True)\n",
    "    if std is None:\n",
    "        std = wav_tensor.std(-1, keepdim=True)\n",
    "    return (wav_tensor - mean) / (std + eps)\n",
    "\n",
    "def get_model(model_info, is_gpu=False):\n",
    "    if model_info['model_path'] is None:\n",
    "        model = sep_former_separator.from_hparams(source=\"speechbrain/sepformer-wsj02mix\", \n",
    "                                       savedir='pretrained_models/sepformer-wsj02mix',\n",
    "                                       run_opts={\"device\":\"cuda\"})\n",
    "        model_name = \"Sepformer\"\n",
    "    else:\n",
    "        model = torch.load(model_info['model_path'])\n",
    "        model_name = model_info['model_path'].split('/')[-1]\n",
    "    return model, model_name\n",
    "\n",
    "results_dic = {}\n",
    "\n",
    "for model_info in models_to_eval:\n",
    "    model, model_name = get_model(model_info, is_gpu=True)\n",
    "    model.cuda()\n",
    "    print(\"======================\")\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    \n",
    "    results_dic[model_name] = {}\n",
    "    \n",
    "    if model_info['test_dataset'] == \"WSJ02mix\":\n",
    "        mixture_paths = wsj02mix_test_file_names\n",
    "    else:\n",
    "        mixture_paths = whamrexcl_test_file_names\n",
    "    \n",
    "    for chosen_mixture_path in tqdm(mixture_paths):\n",
    "        input_mix, gt_sources = get_tensors_for_chosen_file(chosen_mixture_path)\n",
    "        input_mix = input_mix.cuda()\n",
    "        if model_info['is_sudo_model']:\n",
    "            input_mix_std = input_mix.std(-1, keepdim=True)\n",
    "            input_mix_mean = input_mix.mean(-1, keepdim=True)\n",
    "            input_mix = (input_mix - input_mix_mean) / (input_mix_std + 1e-9)\n",
    "            est_sources = model(input_mix.unsqueeze(1))\n",
    "        else:\n",
    "            est_sources = model(input_mix).permute(0, 2, 1)\n",
    "            \n",
    "        try:\n",
    "            all_metrics_dic = get_metrics(\n",
    "                input_mix.detach().cpu().numpy(),\n",
    "                normalize_tensor_wav(gt_sources).detach().cpu().numpy(),\n",
    "                normalize_tensor_wav(est_sources[0]).detach().cpu().numpy(),\n",
    "                compute_permutation=True, sample_rate=8000, metrics_list='all')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        for k, v in all_metrics_dic.items():\n",
    "            if k not in results_dic[model_name]:\n",
    "                results_dic[model_name][k] = [v]\n",
    "            else:\n",
    "                results_dic[model_name][k].append(v)\n",
    "        if 'sisdri' in results_dic[model_name]:\n",
    "            results_dic[model_name]['sisdri'].append(all_metrics_dic['si_sdr'] - all_metrics_dic['input_si_sdr'])\n",
    "        else:\n",
    "            results_dic[model_name]['sisdri'] = [all_metrics_dic['si_sdr'] - all_metrics_dic['input_si_sdr']]\n",
    "            \n",
    "        del est_sources, input_mix\n",
    "    with open(f'{model_name}_sep_perf_models.pickle', 'wb') as handle:\n",
    "        pickle.dump(results_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    del model\n",
    "    \n",
    "pprint(results_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sep_perf_models.pickle', 'rb') as handle:\n",
    "    pprint(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-shock",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
